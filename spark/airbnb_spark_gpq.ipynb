{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f690fbdd",
   "metadata": {},
   "source": [
    "After going thorugh metadata, I found out the listings' prices are stored relevant to each country local currency, in order to use the price column in my dashboard, and becides transformation I made using Mage, I decided to use spark and pyspark this time to convert all prices to usd."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "16c31534",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.functions import udf, col\n",
    "from pyspark.sql.functions import avg\n",
    "from pyspark.sql.types import FloatType\n",
    "from pyspark.conf import SparkConf\n",
    "from pyspark.context import SparkContext"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9de3ac1e",
   "metadata": {},
   "source": [
    "credentials_location = '/home/sal/git/data-engineering-capstone/spark/keys/my-creds.json'\n",
    "\n",
    "conf = SparkConf() \\\n",
    "    .setMaster('local[*]') \\\n",
    "    .setAppName('airbnb') \\\n",
    "    .set(\"spark.jars\", \"./lib/gcs-connector-hadoop3-2.2.5.jar\") \\\n",
    "    .set(\"spark.hadoop.google.cloud.auth.service.account.enable\", \"true\") \\\n",
    "    .set(\"spark.hadoop.google.cloud.auth.service.account.json.keyfile\", credentials_location)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "392bd066",
   "metadata": {},
   "source": [
    "sc = SparkContext(conf=conf)\n",
    "\n",
    "hadoop_conf = sc._jsc.hadoopConfiguration()\n",
    "\n",
    "hadoop_conf.set(\"fs.AbstractFileSystem.gs.impl\",  \"com.google.cloud.hadoop.fs.gcs.GoogleHadoopFS\")\n",
    "hadoop_conf.set(\"fs.gs.impl\", \"com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystem\")\n",
    "hadoop_conf.set(\"fs.gs.auth.service.account.json.keyfile\", credentials_location)\n",
    "hadoop_conf.set(\"fs.gs.auth.service.account.enable\", \"true\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a465f810",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":: loading settings :: url = jar:file:/home/sal/spark/spark-3.5.0-bin-hadoop3/jars/ivy-2.5.1.jar!/org/apache/ivy/core/settings/ivysettings.xml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ivy Default Cache set to: /home/sal/.ivy2/cache\n",
      "The jars for the packages stored in: /home/sal/.ivy2/jars\n",
      "com.google.cloud.spark#spark-3.3-bigquery added as a dependency\n",
      ":: resolving dependencies :: org.apache.spark#spark-submit-parent-18fc1f3d-97a9-46f8-a965-e1bcffb45ade;1.0\n",
      "\tconfs: [default]\n",
      "\tfound com.google.cloud.spark#spark-3.3-bigquery;0.37.0 in central\n",
      "\tfound com.google.cloud.spark#spark-bigquery-dsv2-common;0.37.0 in central\n",
      "\tfound com.google.cloud.spark#spark-bigquery-connector-common;0.37.0 in central\n",
      "\tfound com.google.cloud.spark#bigquery-connector-common;0.37.0 in central\n",
      "\tfound com.google.api.grpc#grpc-google-cloud-bigquerystorage-v1;3.3.1 in central\n",
      "\tfound io.grpc#grpc-api;1.62.2 in central\n",
      "\tfound com.google.code.findbugs#jsr305;3.0.2 in central\n",
      "\tfound com.google.errorprone#error_prone_annotations;2.23.0 in central\n",
      "\tfound io.grpc#grpc-stub;1.62.2 in central\n",
      "\tfound io.grpc#grpc-protobuf;1.62.2 in central\n",
      "\tfound com.google.api.grpc#proto-google-common-protos;2.36.0 in central\n",
      "\tfound com.google.protobuf#protobuf-java;3.25.3 in central\n",
      "\tfound com.google.api.grpc#proto-google-cloud-bigquerystorage-v1;3.3.1 in central\n",
      "\tfound com.google.api#api-common;2.28.0 in central\n",
      "\tfound com.google.auto.value#auto-value-annotations;1.10.4 in central\n",
      "\tfound javax.annotation#javax.annotation-api;1.3.2 in central\n",
      "\tfound com.google.guava#guava;33.0.0-jre in central\n",
      "\tfound com.google.guava#failureaccess;1.0.1 in central\n",
      "\tfound com.google.guava#listenablefuture;9999.0-empty-to-avoid-conflict-with-guava in central\n",
      "\tfound org.checkerframework#checker-qual;3.42.0 in central\n",
      "\tfound com.google.j2objc#j2objc-annotations;2.8 in central\n",
      "\tfound com.google.cloud#google-cloud-bigquery;2.38.1 in central\n",
      "\tfound com.google.cloud#google-cloud-core;2.35.0 in central\n",
      "\tfound com.google.protobuf#protobuf-java-util;3.25.3 in central\n",
      "\tfound com.google.api.grpc#proto-google-iam-v1;1.31.0 in central\n",
      "\tfound com.google.cloud#google-cloud-core-http;2.35.0 in central\n",
      "\tfound com.google.api-client#google-api-client;2.3.0 in central\n",
      "\tfound com.google.oauth-client#google-oauth-client;1.35.0 in central\n",
      "\tfound com.google.http-client#google-http-client-apache-v2;1.44.1 in central\n",
      "\tfound com.google.http-client#google-http-client-appengine;1.44.1 in central\n",
      "\tfound com.google.api#gax-httpjson;2.45.0 in central\n",
      "\tfound io.opencensus#opencensus-api;0.31.1 in central\n",
      "\tfound io.opencensus#opencensus-contrib-http-util;0.31.1 in central\n",
      "\tfound com.google.http-client#google-http-client-gson;1.44.1 in central\n",
      "\tfound com.google.http-client#google-http-client;1.44.1 in central\n",
      "\tfound org.apache.httpcomponents#httpclient;4.5.14 in central\n",
      "\tfound org.apache.httpcomponents#httpcore;4.4.16 in central\n",
      "\tfound io.grpc#grpc-context;1.62.2 in central\n",
      "\tfound org.checkerframework#checker-compat-qual;2.5.6 in central\n",
      "\tfound com.google.auth#google-auth-library-credentials;1.23.0 in central\n",
      "\tfound com.google.auth#google-auth-library-oauth2-http;1.23.0 in central\n",
      "\tfound com.google.apis#google-api-services-bigquery;v2-rev20240211-2.0.0 in central\n",
      "\tfound com.google.api#gax;2.45.0 in central\n",
      "\tfound org.threeten#threetenbp;1.6.8 in central\n",
      "\tfound org.threeten#threeten-extra;1.7.2 in central\n",
      "\tfound com.google.cloud#google-cloud-bigquerystorage;3.3.1 in central\n",
      "\tfound io.grpc#grpc-util;1.62.2 in central\n",
      "\tfound io.grpc#grpc-core;1.62.2 in central\n",
      "\tfound com.google.auto.value#auto-value;1.10.4 in central\n",
      "\tfound com.google.api#gax-grpc;2.45.0 in central\n",
      "\tfound io.grpc#grpc-inprocess;1.62.2 in central\n",
      "\tfound io.grpc#grpc-alts;1.62.2 in central\n",
      "\tfound io.grpc#grpc-grpclb;1.62.2 in central\n",
      "\tfound org.conscrypt#conscrypt-openjdk-uber;2.5.2 in central\n",
      "\tfound io.grpc#grpc-auth;1.62.2 in central\n",
      "\tfound org.json#json;20231013 in central\n",
      "\tfound commons-codec#commons-codec;1.16.0 in central\n",
      "\tfound io.grpc#grpc-netty-shaded;1.62.2 in central\n",
      "\tfound org.apache.arrow#arrow-vector;15.0.1 in central\n",
      "\tfound com.fasterxml.jackson.core#jackson-core;2.16.2 in central\n",
      "\tfound com.fasterxml.jackson.core#jackson-annotations;2.16.2 in central\n",
      "\tfound com.fasterxml.jackson.core#jackson-databind;2.16.2 in central\n",
      "\tfound com.fasterxml.jackson.datatype#jackson-datatype-jsr310;2.16.2 in central\n",
      "\tfound com.google.flatbuffers#flatbuffers-java;23.5.26 in central\n",
      "\tfound org.slf4j#slf4j-api;2.0.9 in central\n",
      "\tfound org.eclipse.collections#eclipse-collections;11.1.0 in central\n",
      "\tfound org.eclipse.collections#eclipse-collections-api;11.1.0 in central\n",
      "\tfound org.apache.arrow#arrow-format;15.0.0 in central\n",
      "\tfound org.apache.arrow#arrow-memory-core;15.0.0 in central\n",
      "\tfound com.google.inject#guice;5.1.0 in central\n",
      "\tfound javax.inject#javax.inject;1 in central\n",
      "\tfound aopalliance#aopalliance;1.0 in central\n",
      "\tfound io.grpc#grpc-netty;1.62.2 in central\n",
      "\tfound io.netty#netty-codec-http2;4.1.107.Final in central\n",
      "\tfound io.netty#netty-common;4.1.107.Final in central\n",
      "\tfound io.netty#netty-buffer;4.1.107.Final in central\n",
      "\tfound io.netty#netty-transport;4.1.107.Final in central\n",
      "\tfound io.netty#netty-resolver;4.1.107.Final in central\n",
      "\tfound io.netty#netty-codec;4.1.107.Final in central\n",
      "\tfound io.netty#netty-handler;4.1.107.Final in central\n",
      "\tfound io.netty#netty-transport-native-unix-common;4.1.107.Final in central\n",
      "\tfound io.netty#netty-codec-http;4.1.107.Final in central\n",
      "\tfound io.netty#netty-tcnative-boringssl-static;2.0.61.Final in central\n",
      "\tfound io.netty#netty-tcnative-classes;2.0.61.Final in central\n",
      "\tfound org.apache.arrow#arrow-memory-netty;15.0.1 in central\n",
      "\tfound com.google.code.gson#gson;2.9.1 in central\n",
      "\tfound org.apache.beam#beam-sdks-java-io-hadoop-common;2.43.0 in central\n",
      "\tfound org.apache.arrow#arrow-compression;15.0.1 in central\n",
      "\tfound org.apache.commons#commons-compress;1.26.0 in central\n",
      "\tfound commons-io#commons-io;2.15.1 in central\n",
      "\tfound org.apache.commons#commons-lang3;3.14.0 in central\n",
      "\tfound com.github.luben#zstd-jni;1.4.9-1 in central\n",
      "\tfound io.grpc#grpc-protobuf-lite;1.62.2 in central\n",
      "\tfound com.google.android#annotations;4.1.1.4 in central\n",
      "\tfound io.perfmark#perfmark-api;0.27.0 in central\n",
      "\tfound org.codehaus.mojo#animal-sniffer-annotations;1.23 in central\n",
      "\tfound io.grpc#grpc-googleapis;1.62.2 in central\n",
      "\tfound io.netty#netty-handler-proxy;4.1.107.Final in central\n",
      "\tfound io.netty#netty-codec-socks;4.1.107.Final in central\n",
      ":: resolution report :: resolve 4755ms :: artifacts dl 74ms\n",
      "\t:: modules in use:\n",
      "\taopalliance#aopalliance;1.0 from central in [default]\n",
      "\tcom.fasterxml.jackson.core#jackson-annotations;2.16.2 from central in [default]\n",
      "\tcom.fasterxml.jackson.core#jackson-core;2.16.2 from central in [default]\n",
      "\tcom.fasterxml.jackson.core#jackson-databind;2.16.2 from central in [default]\n",
      "\tcom.fasterxml.jackson.datatype#jackson-datatype-jsr310;2.16.2 from central in [default]\n",
      "\tcom.github.luben#zstd-jni;1.4.9-1 from central in [default]\n",
      "\tcom.google.android#annotations;4.1.1.4 from central in [default]\n",
      "\tcom.google.api#api-common;2.28.0 from central in [default]\n",
      "\tcom.google.api#gax;2.45.0 from central in [default]\n",
      "\tcom.google.api#gax-grpc;2.45.0 from central in [default]\n",
      "\tcom.google.api#gax-httpjson;2.45.0 from central in [default]\n",
      "\tcom.google.api-client#google-api-client;2.3.0 from central in [default]\n",
      "\tcom.google.api.grpc#grpc-google-cloud-bigquerystorage-v1;3.3.1 from central in [default]\n",
      "\tcom.google.api.grpc#proto-google-cloud-bigquerystorage-v1;3.3.1 from central in [default]\n",
      "\tcom.google.api.grpc#proto-google-common-protos;2.36.0 from central in [default]\n",
      "\tcom.google.api.grpc#proto-google-iam-v1;1.31.0 from central in [default]\n",
      "\tcom.google.apis#google-api-services-bigquery;v2-rev20240211-2.0.0 from central in [default]\n",
      "\tcom.google.auth#google-auth-library-credentials;1.23.0 from central in [default]\n",
      "\tcom.google.auth#google-auth-library-oauth2-http;1.23.0 from central in [default]\n",
      "\tcom.google.auto.value#auto-value;1.10.4 from central in [default]\n",
      "\tcom.google.auto.value#auto-value-annotations;1.10.4 from central in [default]\n",
      "\tcom.google.cloud#google-cloud-bigquery;2.38.1 from central in [default]\n",
      "\tcom.google.cloud#google-cloud-bigquerystorage;3.3.1 from central in [default]\n",
      "\tcom.google.cloud#google-cloud-core;2.35.0 from central in [default]\n",
      "\tcom.google.cloud#google-cloud-core-http;2.35.0 from central in [default]\n",
      "\tcom.google.cloud.spark#bigquery-connector-common;0.37.0 from central in [default]\n",
      "\tcom.google.cloud.spark#spark-3.3-bigquery;0.37.0 from central in [default]\n",
      "\tcom.google.cloud.spark#spark-bigquery-connector-common;0.37.0 from central in [default]\n",
      "\tcom.google.cloud.spark#spark-bigquery-dsv2-common;0.37.0 from central in [default]\n",
      "\tcom.google.code.findbugs#jsr305;3.0.2 from central in [default]\n",
      "\tcom.google.code.gson#gson;2.9.1 from central in [default]\n",
      "\tcom.google.errorprone#error_prone_annotations;2.23.0 from central in [default]\n",
      "\tcom.google.flatbuffers#flatbuffers-java;23.5.26 from central in [default]\n",
      "\tcom.google.guava#failureaccess;1.0.1 from central in [default]\n",
      "\tcom.google.guava#guava;33.0.0-jre from central in [default]\n",
      "\tcom.google.guava#listenablefuture;9999.0-empty-to-avoid-conflict-with-guava from central in [default]\n",
      "\tcom.google.http-client#google-http-client;1.44.1 from central in [default]\n",
      "\tcom.google.http-client#google-http-client-apache-v2;1.44.1 from central in [default]\n",
      "\tcom.google.http-client#google-http-client-appengine;1.44.1 from central in [default]\n",
      "\tcom.google.http-client#google-http-client-gson;1.44.1 from central in [default]\n",
      "\tcom.google.inject#guice;5.1.0 from central in [default]\n",
      "\tcom.google.j2objc#j2objc-annotations;2.8 from central in [default]\n",
      "\tcom.google.oauth-client#google-oauth-client;1.35.0 from central in [default]\n",
      "\tcom.google.protobuf#protobuf-java;3.25.3 from central in [default]\n",
      "\tcom.google.protobuf#protobuf-java-util;3.25.3 from central in [default]\n",
      "\tcommons-codec#commons-codec;1.16.0 from central in [default]\n",
      "\tcommons-io#commons-io;2.15.1 from central in [default]\n",
      "\tio.grpc#grpc-alts;1.62.2 from central in [default]\n",
      "\tio.grpc#grpc-api;1.62.2 from central in [default]\n",
      "\tio.grpc#grpc-auth;1.62.2 from central in [default]\n",
      "\tio.grpc#grpc-context;1.62.2 from central in [default]\n",
      "\tio.grpc#grpc-core;1.62.2 from central in [default]\n",
      "\tio.grpc#grpc-googleapis;1.62.2 from central in [default]\n",
      "\tio.grpc#grpc-grpclb;1.62.2 from central in [default]\n",
      "\tio.grpc#grpc-inprocess;1.62.2 from central in [default]\n",
      "\tio.grpc#grpc-netty;1.62.2 from central in [default]\n",
      "\tio.grpc#grpc-netty-shaded;1.62.2 from central in [default]\n",
      "\tio.grpc#grpc-protobuf;1.62.2 from central in [default]\n",
      "\tio.grpc#grpc-protobuf-lite;1.62.2 from central in [default]\n",
      "\tio.grpc#grpc-stub;1.62.2 from central in [default]\n",
      "\tio.grpc#grpc-util;1.62.2 from central in [default]\n",
      "\tio.netty#netty-buffer;4.1.107.Final from central in [default]\n",
      "\tio.netty#netty-codec;4.1.107.Final from central in [default]\n",
      "\tio.netty#netty-codec-http;4.1.107.Final from central in [default]\n",
      "\tio.netty#netty-codec-http2;4.1.107.Final from central in [default]\n",
      "\tio.netty#netty-codec-socks;4.1.107.Final from central in [default]\n",
      "\tio.netty#netty-common;4.1.107.Final from central in [default]\n",
      "\tio.netty#netty-handler;4.1.107.Final from central in [default]\n",
      "\tio.netty#netty-handler-proxy;4.1.107.Final from central in [default]\n",
      "\tio.netty#netty-resolver;4.1.107.Final from central in [default]\n",
      "\tio.netty#netty-tcnative-boringssl-static;2.0.61.Final from central in [default]\n",
      "\tio.netty#netty-tcnative-classes;2.0.61.Final from central in [default]\n",
      "\tio.netty#netty-transport;4.1.107.Final from central in [default]\n",
      "\tio.netty#netty-transport-native-unix-common;4.1.107.Final from central in [default]\n",
      "\tio.opencensus#opencensus-api;0.31.1 from central in [default]\n",
      "\tio.opencensus#opencensus-contrib-http-util;0.31.1 from central in [default]\n",
      "\tio.perfmark#perfmark-api;0.27.0 from central in [default]\n",
      "\tjavax.annotation#javax.annotation-api;1.3.2 from central in [default]\n",
      "\tjavax.inject#javax.inject;1 from central in [default]\n",
      "\torg.apache.arrow#arrow-compression;15.0.1 from central in [default]\n",
      "\torg.apache.arrow#arrow-format;15.0.0 from central in [default]\n",
      "\torg.apache.arrow#arrow-memory-core;15.0.0 from central in [default]\n",
      "\torg.apache.arrow#arrow-memory-netty;15.0.1 from central in [default]\n",
      "\torg.apache.arrow#arrow-vector;15.0.1 from central in [default]\n",
      "\torg.apache.beam#beam-sdks-java-io-hadoop-common;2.43.0 from central in [default]\n",
      "\torg.apache.commons#commons-compress;1.26.0 from central in [default]\n",
      "\torg.apache.commons#commons-lang3;3.14.0 from central in [default]\n",
      "\torg.apache.httpcomponents#httpclient;4.5.14 from central in [default]\n",
      "\torg.apache.httpcomponents#httpcore;4.4.16 from central in [default]\n",
      "\torg.checkerframework#checker-compat-qual;2.5.6 from central in [default]\n",
      "\torg.checkerframework#checker-qual;3.42.0 from central in [default]\n",
      "\torg.codehaus.mojo#animal-sniffer-annotations;1.23 from central in [default]\n",
      "\torg.conscrypt#conscrypt-openjdk-uber;2.5.2 from central in [default]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\torg.eclipse.collections#eclipse-collections;11.1.0 from central in [default]\n",
      "\torg.eclipse.collections#eclipse-collections-api;11.1.0 from central in [default]\n",
      "\torg.json#json;20231013 from central in [default]\n",
      "\torg.slf4j#slf4j-api;2.0.9 from central in [default]\n",
      "\torg.threeten#threeten-extra;1.7.2 from central in [default]\n",
      "\torg.threeten#threetenbp;1.6.8 from central in [default]\n",
      "\t:: evicted modules:\n",
      "\tcom.google.code.gson#gson;2.10.1 by [com.google.code.gson#gson;2.9.1] in [default]\n",
      "\torg.apache.arrow#arrow-format;15.0.1 by [org.apache.arrow#arrow-format;15.0.0] in [default]\n",
      "\torg.apache.arrow#arrow-memory-core;15.0.1 by [org.apache.arrow#arrow-memory-core;15.0.0] in [default]\n",
      "\torg.checkerframework#checker-qual;3.10.0 by [org.checkerframework#checker-qual;3.42.0] in [default]\n",
      "\tcom.google.guava#failureaccess;1.0.2 by [com.google.guava#failureaccess;1.0.1] in [default]\n",
      "\torg.checkerframework#checker-qual;3.41.0 by [org.checkerframework#checker-qual;3.42.0] in [default]\n",
      "\tio.perfmark#perfmark-api;0.26.0 by [io.perfmark#perfmark-api;0.27.0] in [default]\n",
      "\t---------------------------------------------------------------------\n",
      "\t|                  |            modules            ||   artifacts   |\n",
      "\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|\n",
      "\t---------------------------------------------------------------------\n",
      "\t|      default     |  106  |   0   |   0   |   7   ||   99  |   0   |\n",
      "\t---------------------------------------------------------------------\n",
      ":: retrieving :: org.apache.spark#spark-submit-parent-18fc1f3d-97a9-46f8-a965-e1bcffb45ade\n",
      "\tconfs: [default]\n",
      "\t0 artifacts copied, 99 already retrieved (0kB/39ms)\n",
      "24/04/14 18:23:04 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/04/14 18:23:06 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder \\\n",
    "  .appName('Airbnb') \\\n",
    "  .config('spark.jars.packages', 'com.google.cloud.spark:spark-3.3-bigquery:0.37.0') \\\n",
    "  .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "73e99830",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/04/14 18:23:14 WARN DefaultCredentialsProvider: You are authenticating using user credentials. For production, we recommend using service account credentials.\n",
      "\n",
      "To learn more about service account credentials, see http://cloud.google.com/docs/authentication/external/set-up-adc-on-cloud\n"
     ]
    }
   ],
   "source": [
    "df = spark.read \\\n",
    "        .format(\"bigquery\") \\\n",
    "        .option(\"table\", \"airbnb-de-project.airbnb_dw.airbnb_data\") \\\n",
    "        .load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4d9bfb22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- listing_id: long (nullable = true)\n",
      " |-- host_id: long (nullable = true)\n",
      " |-- host_since: string (nullable = true)\n",
      " |-- host_response_rate: double (nullable = true)\n",
      " |-- host_is_superhost: string (nullable = true)\n",
      " |-- host_total_listings_count: long (nullable = true)\n",
      " |-- host_has_profile_pic: string (nullable = true)\n",
      " |-- host_identity_verified: string (nullable = true)\n",
      " |-- neighbourhood: string (nullable = true)\n",
      " |-- district: string (nullable = true)\n",
      " |-- city: string (nullable = true)\n",
      " |-- latitude: double (nullable = true)\n",
      " |-- longitude: double (nullable = true)\n",
      " |-- property_type: string (nullable = true)\n",
      " |-- room_type: string (nullable = true)\n",
      " |-- accommodates: long (nullable = true)\n",
      " |-- bedrooms: long (nullable = true)\n",
      " |-- price: long (nullable = true)\n",
      " |-- review_scores_rating: long (nullable = true)\n",
      " |-- review_scores_accuracy: long (nullable = true)\n",
      " |-- review_scores_cleanliness: long (nullable = true)\n",
      " |-- review_scores_checkin: long (nullable = true)\n",
      " |-- review_scores_communication: long (nullable = true)\n",
      " |-- review_scores_location: long (nullable = true)\n",
      " |-- review_scores_value: long (nullable = true)\n",
      " |-- price_usd: double (nullable = true)\n",
      " |-- review_id: long (nullable = true)\n",
      " |-- reviewer_id: long (nullable = true)\n",
      " |-- review_date: string (nullable = true)\n",
      " |-- listing_review_count: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cae8bc59",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/04/14 18:23:21 WARN SparkStringUtils: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------+----------------+------------------+-----------------+-------------------------+--------------------+----------------------+-------------+--------+--------------+---------+---------+--------------------+------------+------------+--------+-----+--------------------+----------------------+-------------------------+---------------------+---------------------------+----------------------+-------------------+---------+---------+-----------+----------------+--------------------+\n",
      "|listing_id|  host_id|      host_since|host_response_rate|host_is_superhost|host_total_listings_count|host_has_profile_pic|host_identity_verified|neighbourhood|district|          city| latitude|longitude|       property_type|   room_type|accommodates|bedrooms|price|review_scores_rating|review_scores_accuracy|review_scores_cleanliness|review_scores_checkin|review_scores_communication|review_scores_location|review_scores_value|price_usd|review_id|reviewer_id|     review_date|listing_review_count|\n",
      "+----------+---------+----------------+------------------+-----------------+-------------------------+--------------------+----------------------+-------------+--------+--------------+---------+---------+--------------------+------------+------------+--------+-----+--------------------+----------------------+-------------------------+---------------------+---------------------------+----------------------+-------------------+---------+---------+-----------+----------------+--------------------+\n",
      "|  37200137| 77212938|2018-06-12T00:00|               1.0|                t|                        2|                   t|                     t|          Joa|    NULL|Rio de Janeiro|-23.01489|-43.29168|  Entire condominium|Entire place|           6|       3|  480|                 100|                    10|                       10|                   10|                         10|                    10|                 10|     96.0|607725284|  107166188|2022-02-18T00:00|                  44|\n",
      "|   1792409|  9403945|2015-10-13T00:00|               1.0|                t|                        1|                   t|                     t|          Joa|    NULL|Rio de Janeiro|  -23.014|-43.29163|  Entire condominium|Entire place|           8|       4| 1000|                  98|                    10|                        9|                   10|                         10|                    10|                 10|    200.0|570395343|   75206771|2021-11-29T00:00|                  63|\n",
      "|  25533793| 25815097|2017-01-08T00:00|               1.0|                t|                        1|                   t|                     t|          Joa|    NULL|Rio de Janeiro|-23.01264|-43.29111|        Entire house|Entire place|          12|       4| 1254|                  98|                    10|                        9|                   10|                         10|                    10|                  9|    250.8|444997299|   39699363|2021-04-28T00:00|                  71|\n",
      "|  25533793| 25815097|2017-01-08T00:00|               1.0|                t|                        1|                   t|                     t|          Joa|    NULL|Rio de Janeiro|-23.01264|-43.29111|        Entire house|Entire place|          12|       4| 1254|                  98|                    10|                        9|                   10|                         10|                    10|                  9|    250.8|477091542|   53832258|2021-06-27T00:00|                  71|\n",
      "|  25533793| 25815097|2017-01-08T00:00|               1.0|                t|                        1|                   t|                     t|          Joa|    NULL|Rio de Janeiro|-23.01264|-43.29111|        Entire house|Entire place|          12|       4| 1254|                  98|                    10|                        9|                   10|                         10|                    10|                  9|    250.8|350816081|  222597126|2020-11-20T00:00|                  71|\n",
      "|  25533793| 25815097|2017-01-08T00:00|               1.0|                t|                        1|                   t|                     t|          Joa|    NULL|Rio de Janeiro|-23.01264|-43.29111|        Entire house|Entire place|          12|       4| 1254|                  98|                    10|                        9|                   10|                         10|                    10|                  9|    250.8|622468593|  132369278|2022-04-15T00:00|                  71|\n",
      "|  25533793| 25815097|2017-01-08T00:00|               1.0|                t|                        1|                   t|                     t|          Joa|    NULL|Rio de Janeiro|-23.01264|-43.29111|        Entire house|Entire place|          12|       4| 1254|                  98|                    10|                        9|                   10|                         10|                    10|                  9|    250.8|471930637|  137533799|2021-06-18T00:00|                  71|\n",
      "|  25533793| 25815097|2017-01-08T00:00|               1.0|                t|                        1|                   t|                     t|          Joa|    NULL|Rio de Janeiro|-23.01264|-43.29111|        Entire house|Entire place|          12|       4| 1254|                  98|                    10|                        9|                   10|                         10|                    10|                  9|    250.8|336641037|  127542733|2020-10-14T00:00|                  71|\n",
      "|  40532639|301071932|2021-10-08T00:00|               0.9|                f|                        2|                   t|                     t|          Joa|    NULL|Rio de Janeiro|-23.01346|-43.29173|  Entire condominium|Entire place|           6|       3| 1500|                 100|                    10|                       10|                   10|                         10|                    10|                  9|    300.0|723398493|   83800620|2023-01-10T00:00|                   3|\n",
      "|  25673391|193270591|2020-06-03T00:00|              0.97|                f|                        3|                   t|                     t|          Joa|    NULL|Rio de Janeiro|-23.01033|-43.28817|        Entire villa|Entire place|          12|       6| 6500|                  96|                    10|                        9|                   10|                         10|                    10|                  8|   1300.0|357037707|   13695014|2020-12-09T00:00|                   6|\n",
      "|   2798890| 14315601|2016-04-15T00:00|              0.76|                f|                       50|                   t|                     t|          Joa|    NULL|Rio de Janeiro|-23.01247| -43.2889|        Entire house|Entire place|          15|       6| 5000|                  91|                     9|                        8|                   10|                         10|                    10|                  9|   1000.0|577441944|   11045739|2021-12-15T00:00|                  10|\n",
      "|  16841094| 14315601|2016-04-15T00:00|              0.76|                f|                       50|                   t|                     t|          Joa|    NULL|Rio de Janeiro|-23.01112|-43.28766|        Entire villa|Entire place|          15|       7| 4500|                 100|                    10|                       10|                   10|                         10|                    10|                 10|    900.0|229229500|   24015238|2020-01-22T00:00|                   1|\n",
      "|   2435260| 12446817|2016-02-21T00:00|               1.0|                f|                        3|                   t|                     f|          Joa|    NULL|Rio de Janeiro|-23.00944|-43.28819|Private room in h...|Private room|           2|       1|  300|                 100|                    10|                       10|                   10|                         10|                    10|                  8|     60.0|539016170|  285808834|2021-09-30T00:00|                   1|\n",
      "|   2186329| 11148144|2016-01-09T00:00|               1.0|                t|                        3|                   t|                     t|          Joa|    NULL|Rio de Janeiro|-23.01059|-43.29514|  Entire guest suite|Entire place|           4|       1|  300|                  99|                    10|                       10|                   10|                         10|                    10|                 10|     60.0|669631192|  174762041|2022-09-30T00:00|                  41|\n",
      "|   2186329| 11148144|2016-01-09T00:00|               1.0|                t|                        3|                   t|                     t|          Joa|    NULL|Rio de Janeiro|-23.01059|-43.29514|  Entire guest suite|Entire place|           4|       1|  300|                  99|                    10|                       10|                   10|                         10|                    10|                 10|     60.0|728033100|   30832051|2023-01-31T00:00|                  41|\n",
      "|    844070|  2422154|2014-05-20T00:00|               1.0|                t|                        4|                   t|                     t|          Joa|    NULL|Rio de Janeiro|-23.01079|-43.29422|    Entire apartment|Entire place|           2|       1|   88|                 100|                    10|                       10|                   10|                         10|                    10|                 10|     17.6|594957269|   94651111|2022-01-19T00:00|                  10|\n",
      "|    844070|  2422154|2014-05-20T00:00|               1.0|                t|                        4|                   t|                     t|          Joa|    NULL|Rio de Janeiro|-23.01079|-43.29422|    Entire apartment|Entire place|           2|       1|   88|                 100|                    10|                       10|                   10|                         10|                    10|                 10|     17.6|726777192|  223063552|2023-01-25T00:00|                  10|\n",
      "|   9746631| 37332403|2017-07-02T00:00|               1.0|                t|                        4|                   t|                     t|          Joa|    NULL|Rio de Janeiro|-23.01167|-43.28888|        Entire house|Entire place|           8|       4| 3500|                  96|                    10|                       10|                   10|                         10|                    10|                  9|    700.0|135832339|   28775542|2019-03-06T00:00|                 104|\n",
      "|   1681354|  8675255|2015-09-06T00:00|               1.0|                t|                        1|                   t|                     t|          Joa|    NULL|Rio de Janeiro|-23.00972|-43.29268|        Entire house|Entire place|           6|       4| 2643|                  99|                    10|                       10|                   10|                         10|                    10|                 10|    528.6|661609171|   68885202|2022-09-07T00:00|                  49|\n",
      "|   1681354|  8675255|2015-09-06T00:00|               1.0|                t|                        1|                   t|                     t|          Joa|    NULL|Rio de Janeiro|-23.00972|-43.29268|        Entire house|Entire place|           6|       4| 2643|                  99|                    10|                       10|                   10|                         10|                    10|                 10|    528.6|194858496|   53851932|2019-09-17T00:00|                  49|\n",
      "+----------+---------+----------------+------------------+-----------------+-------------------------+--------------------+----------------------+-------------+--------+--------------+---------+---------+--------------------+------------+------------+--------+-----+--------------------+----------------------+-------------------------+---------------------+---------------------------+----------------------+-------------------+---------+---------+-----------+----------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b55bb727",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Row(listing_id=37200137, host_id=77212938, host_since='2018-06-12T00:00', host_response_rate=1.0, host_is_superhost='t', host_total_listings_count=2, host_has_profile_pic='t', host_identity_verified='t', neighbourhood='Joa', district=None, city='Rio de Janeiro', latitude=-23.01489, longitude=-43.29168, property_type='Entire condominium', room_type='Entire place', accommodates=6, bedrooms=3, price=480, review_scores_rating=100, review_scores_accuracy=10, review_scores_cleanliness=10, review_scores_checkin=10, review_scores_communication=10, review_scores_location=10, review_scores_value=10, price_usd=96.0, review_id=607725284, reviewer_id=107166188, review_date='2022-02-18T00:00', listing_review_count=44)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert price to USD\n",
    "\n",
    "# Conversion rates\n",
    "conversion_rates = {\n",
    "    'Paris': 1.07,\n",
    "    'New York': 1,\n",
    "    'Bangkok': 0.027,\n",
    "    'Rio de Janeiro': 0.20,\n",
    "    'Sydney': 0.65,\n",
    "    'Istanbul': 0.031,\n",
    "    'Rome': 1.07,\n",
    "    'Hong Kong': 0.13,\n",
    "    'Mexico City': 0.060,\n",
    "    'Cape Town': 0.053\n",
    "}\n",
    "\n",
    "# Define a UDF (user-defined function) to calculate the converted price\n",
    "@udf(FloatType())\n",
    "def convert_currency(city, price):\n",
    "    return price * conversion_rates.get(city, 1)\n",
    "\n",
    "# Apply the UDF to create a new column \"price_usd\"\n",
    "df = df.withColumn(\"price_usd\", convert_currency(col(\"city\"), col(\"price\")))\n",
    "\n",
    "# Display the updated dataframe\n",
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "abe6ecbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------+----------------+------------------+-----------------+-------------------------+--------------------+----------------------+-------------+--------+--------------+---------+---------+------------------+------------+------------+--------+-----+--------------------+----------------------+-------------------------+---------------------+---------------------------+----------------------+-------------------+---------+---------+-----------+----------------+--------------------+\n",
      "|listing_id| host_id|      host_since|host_response_rate|host_is_superhost|host_total_listings_count|host_has_profile_pic|host_identity_verified|neighbourhood|district|          city| latitude|longitude|     property_type|   room_type|accommodates|bedrooms|price|review_scores_rating|review_scores_accuracy|review_scores_cleanliness|review_scores_checkin|review_scores_communication|review_scores_location|review_scores_value|price_usd|review_id|reviewer_id|     review_date|listing_review_count|\n",
      "+----------+--------+----------------+------------------+-----------------+-------------------------+--------------------+----------------------+-------------+--------+--------------+---------+---------+------------------+------------+------------+--------+-----+--------------------+----------------------+-------------------------+---------------------+---------------------------+----------------------+-------------------+---------+---------+-----------+----------------+--------------------+\n",
      "|  37200137|77212938|2018-06-12T00:00|               1.0|                t|                        2|                   t|                     t|          Joa|    NULL|Rio de Janeiro|-23.01489|-43.29168|Entire condominium|Entire place|           6|       3|  480|                 100|                    10|                       10|                   10|                         10|                    10|                 10|     96.0|607725284|  107166188|2022-02-18T00:00|                  44|\n",
      "|   1792409| 9403945|2015-10-13T00:00|               1.0|                t|                        1|                   t|                     t|          Joa|    NULL|Rio de Janeiro|  -23.014|-43.29163|Entire condominium|Entire place|           8|       4| 1000|                  98|                    10|                        9|                   10|                         10|                    10|                 10|    200.0|570395343|   75206771|2021-11-29T00:00|                  63|\n",
      "|  25533793|25815097|2017-01-08T00:00|               1.0|                t|                        1|                   t|                     t|          Joa|    NULL|Rio de Janeiro|-23.01264|-43.29111|      Entire house|Entire place|          12|       4| 1254|                  98|                    10|                        9|                   10|                         10|                    10|                  9|    250.8|444997299|   39699363|2021-04-28T00:00|                  71|\n",
      "|  25533793|25815097|2017-01-08T00:00|               1.0|                t|                        1|                   t|                     t|          Joa|    NULL|Rio de Janeiro|-23.01264|-43.29111|      Entire house|Entire place|          12|       4| 1254|                  98|                    10|                        9|                   10|                         10|                    10|                  9|    250.8|477091542|   53832258|2021-06-27T00:00|                  71|\n",
      "|  25533793|25815097|2017-01-08T00:00|               1.0|                t|                        1|                   t|                     t|          Joa|    NULL|Rio de Janeiro|-23.01264|-43.29111|      Entire house|Entire place|          12|       4| 1254|                  98|                    10|                        9|                   10|                         10|                    10|                  9|    250.8|350816081|  222597126|2020-11-20T00:00|                  71|\n",
      "+----------+--------+----------------+------------------+-----------------+-------------------------+--------------------+----------------------+-------------+--------+--------------+---------+---------+------------------+------------+------------+--------+-----+--------------------+----------------------+-------------------------+---------------------+---------------------------+----------------------+-------------------+---------+---------+-----------+----------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 2:>                                                          (0 + 1) / 1]\r",
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ce20ec09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+-----+---------+\n",
      "|          city|price|price_usd|\n",
      "+--------------+-----+---------+\n",
      "|Rio de Janeiro|  480|     96.0|\n",
      "|Rio de Janeiro| 1000|    200.0|\n",
      "|Rio de Janeiro| 1254|    250.8|\n",
      "|Rio de Janeiro| 1254|    250.8|\n",
      "|Rio de Janeiro| 1254|    250.8|\n",
      "|Rio de Janeiro| 1254|    250.8|\n",
      "|Rio de Janeiro| 1254|    250.8|\n",
      "|Rio de Janeiro| 1254|    250.8|\n",
      "|Rio de Janeiro| 1500|    300.0|\n",
      "|Rio de Janeiro| 6500|   1300.0|\n",
      "+--------------+-----+---------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select('city', 'price', 'price_usd').show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e246c60c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 4:=======================================>                   (2 + 1) / 3]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+\n",
      "|average_price_usd|\n",
      "+-----------------+\n",
      "|88.78709692960278|\n",
      "+-----------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Calculate the average price_usd\n",
    "avg_price_usd = df.groupBy().agg(avg('price_usd').alias('average_price_usd'))\n",
    "\n",
    "# Show the result\n",
    "avg_price_usd.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8fe13e7e",
   "metadata": {},
   "outputs": [
    {
     "ename": "Py4JJavaError",
     "evalue": "An error occurred while calling o76.save.\n: java.io.UncheckedIOException: org.apache.hadoop.fs.UnsupportedFileSystemException: No FileSystem for scheme \"gs\"\n\tat com.google.cloud.spark.bigquery.SparkBigQueryUtil.createGcsPath(SparkBigQueryUtil.java:129)\n\tat com.google.cloud.spark.bigquery.write.BigQueryWriteHelper.<init>(BigQueryWriteHelper.java:89)\n\tat com.google.cloud.spark.bigquery.write.BigQueryDeprecatedIndirectInsertableRelation.insert(BigQueryDeprecatedIndirectInsertableRelation.java:41)\n\tat com.google.cloud.spark.bigquery.write.CreatableRelationProviderHelper.createRelation(CreatableRelationProviderHelper.java:58)\n\tat com.google.cloud.spark.bigquery.v2.Spark31BigQueryTableProvider.createRelation(Spark31BigQueryTableProvider.java:65)\n\tat org.apache.spark.sql.execution.datasources.SaveIntoDataSourceCommand.run(SaveIntoDataSourceCommand.scala:48)\n\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult$lzycompute(commands.scala:75)\n\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult(commands.scala:73)\n\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.executeCollect(commands.scala:84)\n\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.$anonfun$applyOrElse$1(QueryExecution.scala:107)\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)\n\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)\n\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)\n\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:107)\n\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:98)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformDownWithPruning$1(TreeNode.scala:461)\n\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDownWithPruning(TreeNode.scala:461)\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.org$apache$spark$sql$catalyst$plans$logical$AnalysisHelper$$super$transformDownWithPruning(LogicalPlan.scala:32)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning(AnalysisHelper.scala:267)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning$(AnalysisHelper.scala:263)\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32)\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:437)\n\tat org.apache.spark.sql.execution.QueryExecution.eagerlyExecuteCommands(QueryExecution.scala:98)\n\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted$lzycompute(QueryExecution.scala:85)\n\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted(QueryExecution.scala:83)\n\tat org.apache.spark.sql.execution.QueryExecution.assertCommandExecuted(QueryExecution.scala:142)\n\tat org.apache.spark.sql.DataFrameWriter.runCommand(DataFrameWriter.scala:859)\n\tat org.apache.spark.sql.DataFrameWriter.saveToV1Source(DataFrameWriter.scala:388)\n\tat org.apache.spark.sql.DataFrameWriter.saveInternal(DataFrameWriter.scala:355)\n\tat org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:248)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:566)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n\tat java.base/java.lang.Thread.run(Thread.java:834)\nCaused by: org.apache.hadoop.fs.UnsupportedFileSystemException: No FileSystem for scheme \"gs\"\n\tat org.apache.hadoop.fs.FileSystem.getFileSystemClass(FileSystem.java:3443)\n\tat org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:3466)\n\tat org.apache.hadoop.fs.FileSystem.access$300(FileSystem.java:174)\n\tat org.apache.hadoop.fs.FileSystem$Cache.getInternal(FileSystem.java:3574)\n\tat org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:3521)\n\tat org.apache.hadoop.fs.FileSystem.get(FileSystem.java:540)\n\tat org.apache.hadoop.fs.Path.getFileSystem(Path.java:365)\n\tat com.google.cloud.spark.bigquery.SparkBigQueryUtil.getUniqueGcsPath(SparkBigQueryUtil.java:143)\n\tat com.google.cloud.spark.bigquery.SparkBigQueryUtil.createGcsPath(SparkBigQueryUtil.java:124)\n\t... 45 more\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 18\u001b[0m\n\u001b[1;32m      8\u001b[0m table_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mairbnb_data_spark\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# Write the DataFrame to BigQuery\u001b[39;00m\n\u001b[1;32m     11\u001b[0m df\u001b[38;5;241m.\u001b[39mwrite \\\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbigquery\u001b[39m\u001b[38;5;124m\"\u001b[39m) \\\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;241m.\u001b[39moption(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtemporaryGcsBucket\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mairbnb-data-lake\u001b[39m\u001b[38;5;124m\"\u001b[39m) \\\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;241m.\u001b[39moption(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mproject\u001b[39m\u001b[38;5;124m\"\u001b[39m, project_id) \\\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;241m.\u001b[39moption(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdataset\u001b[39m\u001b[38;5;124m\"\u001b[39m, dataset_name) \\\n\u001b[1;32m     16\u001b[0m     \u001b[38;5;241m.\u001b[39moption(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtable\u001b[39m\u001b[38;5;124m\"\u001b[39m, table_name) \\\n\u001b[1;32m     17\u001b[0m     \u001b[38;5;241m.\u001b[39moption(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcredentialsFile\u001b[39m\u001b[38;5;124m\"\u001b[39m, key_file_path) \\\n\u001b[0;32m---> 18\u001b[0m     \u001b[38;5;241m.\u001b[39msave()\n",
      "File \u001b[0;32m~/spark/spark-3.5.0-bin-hadoop3/python/pyspark/sql/readwriter.py:1461\u001b[0m, in \u001b[0;36mDataFrameWriter.save\u001b[0;34m(self, path, format, mode, partitionBy, **options)\u001b[0m\n\u001b[1;32m   1459\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mformat\u001b[39m)\n\u001b[1;32m   1460\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m path \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1461\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jwrite\u001b[38;5;241m.\u001b[39msave()\n\u001b[1;32m   1462\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1463\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jwrite\u001b[38;5;241m.\u001b[39msave(path)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/py4j/java_gateway.py:1322\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1316\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1317\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1318\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1319\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[1;32m   1321\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client\u001b[38;5;241m.\u001b[39msend_command(command)\n\u001b[0;32m-> 1322\u001b[0m return_value \u001b[38;5;241m=\u001b[39m get_return_value(\n\u001b[1;32m   1323\u001b[0m     answer, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_id, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname)\n\u001b[1;32m   1325\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[1;32m   1326\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(temp_arg, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_detach\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[0;32m~/spark/spark-3.5.0-bin-hadoop3/python/pyspark/errors/exceptions/captured.py:179\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    177\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdeco\u001b[39m(\u001b[38;5;241m*\u001b[39ma: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    178\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 179\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m f(\u001b[38;5;241m*\u001b[39ma, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw)\n\u001b[1;32m    180\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m Py4JJavaError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    181\u001b[0m         converted \u001b[38;5;241m=\u001b[39m convert_exception(e\u001b[38;5;241m.\u001b[39mjava_exception)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/py4j/protocol.py:326\u001b[0m, in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    324\u001b[0m value \u001b[38;5;241m=\u001b[39m OUTPUT_CONVERTER[\u001b[38;5;28mtype\u001b[39m](answer[\u001b[38;5;241m2\u001b[39m:], gateway_client)\n\u001b[1;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m answer[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m REFERENCE_TYPE:\n\u001b[0;32m--> 326\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m Py4JJavaError(\n\u001b[1;32m    327\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn error occurred while calling \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39m\n\u001b[1;32m    328\u001b[0m         \u001b[38;5;28mformat\u001b[39m(target_id, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m, name), value)\n\u001b[1;32m    329\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    330\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m Py4JError(\n\u001b[1;32m    331\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn error occurred while calling \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m. Trace:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{3}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39m\n\u001b[1;32m    332\u001b[0m         \u001b[38;5;28mformat\u001b[39m(target_id, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m, name, value))\n",
      "\u001b[0;31mPy4JJavaError\u001b[0m: An error occurred while calling o76.save.\n: java.io.UncheckedIOException: org.apache.hadoop.fs.UnsupportedFileSystemException: No FileSystem for scheme \"gs\"\n\tat com.google.cloud.spark.bigquery.SparkBigQueryUtil.createGcsPath(SparkBigQueryUtil.java:129)\n\tat com.google.cloud.spark.bigquery.write.BigQueryWriteHelper.<init>(BigQueryWriteHelper.java:89)\n\tat com.google.cloud.spark.bigquery.write.BigQueryDeprecatedIndirectInsertableRelation.insert(BigQueryDeprecatedIndirectInsertableRelation.java:41)\n\tat com.google.cloud.spark.bigquery.write.CreatableRelationProviderHelper.createRelation(CreatableRelationProviderHelper.java:58)\n\tat com.google.cloud.spark.bigquery.v2.Spark31BigQueryTableProvider.createRelation(Spark31BigQueryTableProvider.java:65)\n\tat org.apache.spark.sql.execution.datasources.SaveIntoDataSourceCommand.run(SaveIntoDataSourceCommand.scala:48)\n\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult$lzycompute(commands.scala:75)\n\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult(commands.scala:73)\n\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.executeCollect(commands.scala:84)\n\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.$anonfun$applyOrElse$1(QueryExecution.scala:107)\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)\n\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)\n\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)\n\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:107)\n\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:98)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformDownWithPruning$1(TreeNode.scala:461)\n\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDownWithPruning(TreeNode.scala:461)\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.org$apache$spark$sql$catalyst$plans$logical$AnalysisHelper$$super$transformDownWithPruning(LogicalPlan.scala:32)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning(AnalysisHelper.scala:267)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning$(AnalysisHelper.scala:263)\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32)\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:437)\n\tat org.apache.spark.sql.execution.QueryExecution.eagerlyExecuteCommands(QueryExecution.scala:98)\n\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted$lzycompute(QueryExecution.scala:85)\n\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted(QueryExecution.scala:83)\n\tat org.apache.spark.sql.execution.QueryExecution.assertCommandExecuted(QueryExecution.scala:142)\n\tat org.apache.spark.sql.DataFrameWriter.runCommand(DataFrameWriter.scala:859)\n\tat org.apache.spark.sql.DataFrameWriter.saveToV1Source(DataFrameWriter.scala:388)\n\tat org.apache.spark.sql.DataFrameWriter.saveInternal(DataFrameWriter.scala:355)\n\tat org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:248)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:566)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n\tat java.base/java.lang.Thread.run(Thread.java:834)\nCaused by: org.apache.hadoop.fs.UnsupportedFileSystemException: No FileSystem for scheme \"gs\"\n\tat org.apache.hadoop.fs.FileSystem.getFileSystemClass(FileSystem.java:3443)\n\tat org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:3466)\n\tat org.apache.hadoop.fs.FileSystem.access$300(FileSystem.java:174)\n\tat org.apache.hadoop.fs.FileSystem$Cache.getInternal(FileSystem.java:3574)\n\tat org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:3521)\n\tat org.apache.hadoop.fs.FileSystem.get(FileSystem.java:540)\n\tat org.apache.hadoop.fs.Path.getFileSystem(Path.java:365)\n\tat com.google.cloud.spark.bigquery.SparkBigQueryUtil.getUniqueGcsPath(SparkBigQueryUtil.java:143)\n\tat com.google.cloud.spark.bigquery.SparkBigQueryUtil.createGcsPath(SparkBigQueryUtil.java:124)\n\t... 45 more\n"
     ]
    }
   ],
   "source": [
    "\n",
    "key_file_path = '/home/sal/git/data-engineering-capstone/spark/keys/my-creds.json'\n",
    "\n",
    "# Define the Google Cloud project ID\n",
    "project_id = \"airbnb-dezoomcamp\"\n",
    "\n",
    "# Set the BigQuery dataset and table name\n",
    "dataset_name = \"airbnb_dw\"\n",
    "table_name = \"airbnb_data_spark\"\n",
    "\n",
    "# Write the DataFrame to BigQuery\n",
    "df.write \\\n",
    "    .format(\"bigquery\") \\\n",
    "    .option(\"temporaryGcsBucket\", \"airbnb-data-lake\") \\\n",
    "    .option(\"project\", project_id) \\\n",
    "    .option(\"dataset\", dataset_name) \\\n",
    "    .option(\"table\", table_name) \\\n",
    "    .option(\"credentialsFile\", key_file_path) \\\n",
    "    .save()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d704fb4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write transformed data back to BigQuery\n",
    "df.write \\\n",
    "    .format(\"bigquery\") \\\n",
    "    .option(\"temporaryGcsBucket\", \"airbnb-data-lake\") \\\n",
    "    .option(\"table\", \"airbnb-de-project.airbnb_dw.airbnb_data_spark\") \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fe7e60a",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f0e0245",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
